id: analyze
description: Build prompts for structured analysis and tradeoff reasoning
signature_template: input_context, objective, constraints -> compiled_prompt, checks
prompt_style: structured_behavior_contract
compiler_principles: |
  You are an expert prompt engineer specializing in analytical tasks. Generate a single,
  production-quality system prompt that functions as a complete behavior contract for
  rigorous analysis work.

  ## Generation Principles

  1. **Expert Domain Role**: Open with a role that names the specific domain, technology,
     or analytical lens. A precise identity anchors all downstream reasoning.
  2. **Constraint Fidelity**: Include ONLY constraints explicitly stated or directly implied
     by the intent. Never invent safety rules, platform policies, citation formats, or
     behavioral restrictions not present in the user's request.
  3. **Systematic Methodology**: Define a concrete step-by-step procedure. Tell the analyst
     what to examine, in what order, and how to structure findings.
  4. **Evidence Standards**: Specify what counts as valid evidence. Prefer code references,
     config values, and documented patterns over vague assertions.
  5. **Measurable Criteria**: Replace qualifiers like "thorough" with specific thresholds
     (e.g., "check all files in module X", "cover at least 2 edge cases per item").
  6. **Trade-off Awareness**: Require explicit discussion of trade-offs for any proposal.
     Flag scalability, maintainability, and side-effect concerns.
  7. **Known/Unknown Separation**: Clearly distinguish facts from assumptions from genuine
     unknowns. When context is insufficient, state what is unknown rather than guessing.
  8. **Chain-of-Thought**: Embed reasoning scaffolding for complex analysis. Specify the
     thinking sequence, not just the output structure.
  9. **Adaptive Structure**: Use Markdown headings or semantic XML tags — pick whichever
     best fits the task. Avoid using both for the same section. Only include sections
     that genuinely serve this specific task.
  10. **Output Contract**: End with a testable specification: what the output must contain,
      how to handle inconclusive cases, and what constitutes a complete answer.

  ## Quality Standard

  Every instruction must do work. Be dense with actionable, domain-specific guidance.
  Depth on what the user asked for — never pad with generic advice or boilerplate sections.
refine_principles: |
  You are refining an existing analysis prompt. Apply surgical, targeted improvements —
  do not rewrite from scratch.

  ## Refinement Protocol

  1. **Diagnose First**: Identify the 2-3 highest-impact weaknesses from judge feedback
     and deterministic penalties.
  2. **Preserve What Works**: Keep sections that scored well. Only modify what the feedback
     specifically criticizes.
  3. **Priority Order**: Constraint violations → clarity issues → depth improvements.
     Never sacrifice correctness for style.
  4. **Strip Hallucinations**: Remove any rule, policy, or constraint NOT in the outcome
     spec or user intent. Common hallucinations: invented thresholds, platform policies,
     citation formats, procedural gates the user did not request.
  5. **Strengthen Methodology**: If the analysis method is vague, add concrete steps,
     numbered procedures, or explicit decision criteria from the intent.
  6. **Technique Completeness**: Verify the prompt has a specific domain role, measurable
     instructions, a reasoning sequence, and an output contract.
  7. **Remove Structural Noise**: Replace bracket markup ([Section]) with Markdown or XML.
     Strip envelope tags. Remove duplicate heading+XML for the same section.
prompt_directives:
  - Start with a clear role definition establishing analytical expertise
  - State the mission objective and explicit scope boundaries upfront
  - Use semantic XML tags to organize sections (e.g., <constraints>, <method>, <evidence_bar>, <output_format>, <failure_policy>, <examples>)
  - Separate facts, assumptions, and unknowns so reasoning can be audited
  - Include a step-by-step method with explicit chain-of-thought scaffolding
  - Require evidence standards and cite specific thresholds, not vague qualifiers
  - Include tradeoffs and decision-impacting uncertainties with concrete comparisons
  - End with a testable output contract specifying format, required fields, and failure criteria
  - Be dense and comprehensive — fill the token budget with actionable, specific guidance
  - Do NOT wrap the entire prompt in <system> or <prompt> envelope tags
quality_checklist:
  - objective is concrete, outcome-oriented, and verifiable by a third party
  - ALL constraints come from the user's intent — no hallucinated policies or rules
  - output format is NOT specified unless the user explicitly requested one
  - knowledge level from intent is deeply honored (if 'assume no knowledge', every term explained from basics)
  - assumptions are explicit when context is incomplete
  - method is sequenced with chain-of-thought reasoning steps
  - instructions use measurable criteria from the intent, not invented thresholds
  - output contract reflects the user's actual success criteria
  - role/identity is established in the opening lines
clarification_policy:
  - Ask only for missing details that materially change the analysis result
  - If critical details are missing, ask targeted clarification questions before finalizing
ambiguity_resolution_rules:
  - If ambiguity is low-risk, proceed with explicit assumptions
  - If ambiguity changes recommendations materially, request clarification first
forbidden_patterns:
  - etc
  - as needed
  - single-message only
  - exactly 3 rounds
  - arbitrary word limit
  - forced citation format
  - '[section]'
  - '[[block]]'
  - <system>
friction_markers:
  - in one message
  - single user message
  - maximum two rounds
  - at most two
  - up to three clarification rounds
  - allow up to three clarification attempts
  - interaction will end
  - after two clarification attempts
  - after three clarification attempts
  - "≤\u202f2,000 words"
  - 2,000 words per question
  - cited directly after the statement
  - in parentheses
  - "[instruction_hierarchy]"
  - "[input_boundary]"
  - "[failure_policy]"
  - "[output_contract]"
  - "[final_self_check]"
  - "[[instruction_hierarchy]]"
  - "[[input_boundary]]"
  - "[[failure_policy]]"
  - "[[output_contract]]"
  - "[[final_self_check]]"
  - "<prompt>"
  - "</system>"
required_sections:
  - goal
  - knowns
  - unknowns
  - method
  - evidence_bar
  - tradeoffs
  - output_contract
required_prompt_blocks:
  - instruction_hierarchy
  - input_boundary
  - failure_policy
  - output_contract
  - final_self_check
required_technique_markers:
  - objective
  - constraints
  - method
  - evidence
  - output contract
vague_markers:
  - etc
  - as needed
  - maybe
  - could be
  - various
ambiguity_penalty_per_marker: 0.04
ambiguity_penalty_cap: 0.35
missing_sections_weight: 0.25
missing_techniques_weight: 0.20
eval_weights:
  quality: 0.45
  clarity: 0.25
  constraint_fit: 0.2
  brevity: 0.1
judge_rubric:
  priorities:
    - enforce method and evidence requirements before style
    - penalize missing tradeoffs and weak assumptions
  quality_checks:
    - states explicit objective and analysis method
    - includes evidence standards and tradeoff handling
  clarity_checks:
    - avoids vague qualifiers and ambiguous scope
    - instructions are structured and non-redundant
  constraint_checks:
    - preserves hard constraints and output contract
    - includes required sections from workflow
  risk_checks:
    - flags unsupported claims
    - flags missing decision-critical context
